{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score,precision_score,recall_score\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1118 entries, 0 to 1117\n",
      "Data columns (total 10 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   flair      1118 non-null   object\n",
      " 1   title      1118 non-null   object\n",
      " 2   score      1118 non-null   int64 \n",
      " 3   id         1118 non-null   object\n",
      " 4   url        1118 non-null   object\n",
      " 5   comms_num  1118 non-null   int64 \n",
      " 6   body       677 non-null    object\n",
      " 7   author     1118 non-null   object\n",
      " 8   comments   1019 non-null   object\n",
      " 9   timestamp  1118 non-null   object\n",
      "dtypes: int64(2), object(8)\n",
      "memory usage: 87.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('reddit-india-data.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['comments']=df['comments'].fillna(\"\")\n",
    "df['body']=df['body'].fillna(\"\")\n",
    "df['combined'] = df['title'] + df['body'] + df['comments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I use only title as features and combined features. <br>\n",
    "I use logistic regression, linear svc and randon forest as classifiers. <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification results using Logistic Regression\n",
      "\n",
      "[[19  0  1  0  0  0  0  1  1  0  0  0]\n",
      " [ 0  7  3  1  1  0  2  1  2  0  0  0]\n",
      " [ 0  4 10  0  0  0  5  0  3  1  1  0]\n",
      " [ 0  0  0 13  0  1  0  1  0  0  0  0]\n",
      " [ 1  0  0  0 21  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0 22  0  0  0  0  0  0]\n",
      " [ 0  3  5  0  0  0 11  2  2  1  0  0]\n",
      " [ 0  0  0  0  1  1  2  8  3  0  1  0]\n",
      " [ 1  3  2  0  0  0  1  1  9  1  0  0]\n",
      " [ 0  2  3  1  0  0  0  1  1 10  1  0]\n",
      " [ 0  2  0  0  0  0  1  0  2  0 15  0]\n",
      " [ 0  0  0  0  0  0  0  2  2  0  0  0]]\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "               AMA       0.90      0.86      0.88        22\n",
      "          AskIndia       0.33      0.41      0.37        17\n",
      "  Business/Finance       0.42      0.42      0.42        24\n",
      "              Food       0.87      0.87      0.87        15\n",
      "     Non-Political       0.91      0.91      0.91        23\n",
      "       Photography       0.92      1.00      0.96        22\n",
      "    Policy/Economy       0.50      0.46      0.48        24\n",
      "          Politics       0.44      0.50      0.47        16\n",
      "         Scheduled       0.36      0.50      0.42        18\n",
      "Science/Technology       0.77      0.53      0.62        19\n",
      "            Sports       0.83      0.75      0.79        20\n",
      "     [R]eddiquette       0.00      0.00      0.00         4\n",
      "\n",
      "          accuracy                           0.65       224\n",
      "         macro avg       0.60      0.60      0.60       224\n",
      "      weighted avg       0.65      0.65      0.65       224\n",
      "\n",
      "Accuracy :  0.6473214285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\reddit\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['title'],df['flair'],test_size = 0.2 ,)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "        ('bow', CountVectorizer(  ngram_range=(1,2), stop_words= 'english')),  \n",
    "        ('tfidf', TfidfTransformer()),  \n",
    "        ('c',LogisticRegression())\n",
    "    ])\n",
    "\n",
    "clf1 = pipeline.fit(X_train,y_train)\n",
    "\n",
    "pred=pipeline.predict(X_test)\n",
    "\n",
    "print(\"Classification results using Logistic Regression\\n\")\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print(classification_report(y_test,pred))\n",
    "print(\"Accuracy : \",accuracy_score(pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification results using LinearSVC\n",
      "\n",
      "[[20  1  1  0  0  1  2  0  0  0  0  0]\n",
      " [ 1 10  0  3  1  0  0  0  0  1  1  0]\n",
      " [ 0  0 14  0  0  0  5  1  0  2  0  0]\n",
      " [ 1  1  0 18  0  1  0  0  1  0  0  0]\n",
      " [ 1  2  1  1 10  0  0  3  0  2  0  0]\n",
      " [ 0  0  0  0  2 16  0  0  0  0  0  0]\n",
      " [ 0  0  2  0  0  0 13  1  0  0  0  0]\n",
      " [ 1  0  0  1  0  1  2 12  2  1  0  0]\n",
      " [ 1  1  0  1  0  0  0  1 13  0  0  0]\n",
      " [ 0  1  0  1  0  0  1  1  0 18  0  0]\n",
      " [ 0  0  0  1  0  0  2  1  0  0 18  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  2]]\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "               AMA       0.77      0.80      0.78        25\n",
      "          AskIndia       0.62      0.59      0.61        17\n",
      "  Business/Finance       0.78      0.64      0.70        22\n",
      "              Food       0.69      0.82      0.75        22\n",
      "     Non-Political       0.77      0.50      0.61        20\n",
      "       Photography       0.84      0.89      0.86        18\n",
      "    Policy/Economy       0.52      0.81      0.63        16\n",
      "          Politics       0.60      0.60      0.60        20\n",
      "         Scheduled       0.81      0.76      0.79        17\n",
      "Science/Technology       0.75      0.82      0.78        22\n",
      "            Sports       0.95      0.82      0.88        22\n",
      "     [R]eddiquette       1.00      0.67      0.80         3\n",
      "\n",
      "          accuracy                           0.73       224\n",
      "         macro avg       0.76      0.73      0.73       224\n",
      "      weighted avg       0.75      0.73      0.73       224\n",
      "\n",
      "Accuracy :  0.7321428571428571\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "        ('bow', CountVectorizer(  ngram_range=(1,2), stop_words= 'english')),  \n",
    "        ('tfidf', TfidfTransformer()),  \n",
    "        ('c',LinearSVC())\n",
    "    ])\n",
    "\n",
    "clf2 = pipeline.fit(X_train,y_train)\n",
    "pred=pipeline.predict(X_test)\n",
    "\n",
    "print(\"Classification results using LinearSVC\\n\")\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print(classification_report(y_test,pred))\n",
    "print(\"Accuracy : \",accuracy_score(pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification results using Random Forest\n",
      "[[18  1  0  1  1  0  1  2  1  0  0  0]\n",
      " [ 0  9  0  3  1  2  0  0  0  1  1  0]\n",
      " [ 0  1 13  0  0  1  6  0  0  1  0  0]\n",
      " [ 1  1  0 18  0  1  0  0  1  0  0  0]\n",
      " [ 0  1  1  1 14  0  0  2  0  1  0  0]\n",
      " [ 0  0  0  0  0 18  0  0  0  0  0  0]\n",
      " [ 0  0  2  1  0  0 11  1  1  0  0  0]\n",
      " [ 2  0  0  0  2  0  2 11  3  0  0  0]\n",
      " [ 0  1  0  0  0  0  0  1 15  0  0  0]\n",
      " [ 0  0  2  0  0  0  0  0  0 19  1  0]\n",
      " [ 0  2  0  0  1  1  1  1  1  0 15  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  2]]\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "               AMA       0.82      0.72      0.77        25\n",
      "          AskIndia       0.56      0.53      0.55        17\n",
      "  Business/Finance       0.72      0.59      0.65        22\n",
      "              Food       0.75      0.82      0.78        22\n",
      "     Non-Political       0.74      0.70      0.72        20\n",
      "       Photography       0.78      1.00      0.88        18\n",
      "    Policy/Economy       0.52      0.69      0.59        16\n",
      "          Politics       0.61      0.55      0.58        20\n",
      "         Scheduled       0.68      0.88      0.77        17\n",
      "Science/Technology       0.86      0.86      0.86        22\n",
      "            Sports       0.88      0.68      0.77        22\n",
      "     [R]eddiquette       1.00      0.67      0.80         3\n",
      "\n",
      "          accuracy                           0.73       224\n",
      "         macro avg       0.74      0.72      0.73       224\n",
      "      weighted avg       0.74      0.73      0.73       224\n",
      "\n",
      "Accuracy :  0.7276785714285714\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "        ('bow', CountVectorizer(  ngram_range=(1,2), stop_words= 'english')),  \n",
    "        ('tfidf', TfidfTransformer()),  \n",
    "        ('c',RandomForestClassifier())\n",
    "    ])\n",
    "\n",
    "clf3 = pipeline.fit(X_train,y_train)\n",
    "pred=pipeline.predict(X_test)\n",
    "\n",
    "print(\"Classification results using Random Forest\")\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print(classification_report(y_test,pred))\n",
    "print(\"Accuracy : \",accuracy_score(pred,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification results using Logistic Regression\n",
      "\n",
      "[[17  0  1  0  0  0  2  0  0  0  0  0]\n",
      " [ 2  8  4  1  0  0  0  1  1  2  0  0]\n",
      " [ 0  0 12  0  0  0  4  0  1  1  0  0]\n",
      " [ 0  0  0 19  0  0  0  1  0  0  0  0]\n",
      " [ 3  0  2  2  5  0  0  1  1  1  1  0]\n",
      " [ 0  0  1  0  0 25  0  0  0  1  0  0]\n",
      " [ 2  1  1  0  0  0 17  1  0  0  0  0]\n",
      " [ 2  0  0  4  1  0  0 16  2  0  0  0]\n",
      " [ 5  0  1  0  0  0  0  0 12  0  0  0]\n",
      " [ 2  1  1  0  0  0  0  0  0 16  0  0]\n",
      " [ 2  1  0  0  0  0  0  0  0  0 13  0]\n",
      " [ 2  0  0  0  0  0  0  0  0  0  0  1]]\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "               AMA       0.46      0.85      0.60        20\n",
      "          AskIndia       0.73      0.42      0.53        19\n",
      "  Business/Finance       0.52      0.67      0.59        18\n",
      "              Food       0.73      0.95      0.83        20\n",
      "     Non-Political       0.83      0.31      0.45        16\n",
      "       Photography       1.00      0.93      0.96        27\n",
      "    Policy/Economy       0.74      0.77      0.76        22\n",
      "          Politics       0.80      0.64      0.71        25\n",
      "         Scheduled       0.71      0.67      0.69        18\n",
      "Science/Technology       0.76      0.80      0.78        20\n",
      "            Sports       0.93      0.81      0.87        16\n",
      "     [R]eddiquette       1.00      0.33      0.50         3\n",
      "\n",
      "          accuracy                           0.72       224\n",
      "         macro avg       0.77      0.68      0.69       224\n",
      "      weighted avg       0.76      0.72      0.71       224\n",
      "\n",
      "Accuracy :  0.71875\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['combined'],df['flair'],test_size = 0.2 ,)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "        ('bow', CountVectorizer(  ngram_range=(1,2), stop_words= 'english')),  \n",
    "        ('tfidf', TfidfTransformer()),  \n",
    "        ('c',LogisticRegression())\n",
    "    ])\n",
    "\n",
    "clf4 = pipeline.fit(X_train,y_train)\n",
    "\n",
    "pred=pipeline.predict(X_test)\n",
    "\n",
    "print(\"Classification results using Logistic Regression\\n\")\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print(classification_report(y_test,pred))\n",
    "print(\"Accuracy : \",accuracy_score(pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification results using LinearSVC\n",
      "\n",
      "[[17  0  1  0  0  0  2  0  0  0  0  0]\n",
      " [ 1  7  3  1  0  0  1  1  2  3  0  0]\n",
      " [ 0  0 12  1  0  0  3  0  1  1  0  0]\n",
      " [ 0  0  0 19  0  0  0  1  0  0  0  0]\n",
      " [ 2  1  2  2  5  0  0  1  1  1  1  0]\n",
      " [ 0  0  1  0  0 25  0  0  0  1  0  0]\n",
      " [ 0  2  1  0  0  0 17  2  0  0  0  0]\n",
      " [ 1  0  0  5  0  0  0 18  1  0  0  0]\n",
      " [ 3  0  1  0  0  0  0  0 14  0  0  0]\n",
      " [ 2  0  1  0  0  0  0  1  0 16  0  0]\n",
      " [ 2  0  0  0  0  0  0  0  0  0 14  0]\n",
      " [ 2  0  0  0  0  0  0  0  0  0  0  1]]\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "               AMA       0.57      0.85      0.68        20\n",
      "          AskIndia       0.70      0.37      0.48        19\n",
      "  Business/Finance       0.55      0.67      0.60        18\n",
      "              Food       0.68      0.95      0.79        20\n",
      "     Non-Political       1.00      0.31      0.48        16\n",
      "       Photography       1.00      0.93      0.96        27\n",
      "    Policy/Economy       0.74      0.77      0.76        22\n",
      "          Politics       0.75      0.72      0.73        25\n",
      "         Scheduled       0.74      0.78      0.76        18\n",
      "Science/Technology       0.73      0.80      0.76        20\n",
      "            Sports       0.93      0.88      0.90        16\n",
      "     [R]eddiquette       1.00      0.33      0.50         3\n",
      "\n",
      "          accuracy                           0.74       224\n",
      "         macro avg       0.78      0.70      0.70       224\n",
      "      weighted avg       0.77      0.74      0.73       224\n",
      "\n",
      "Accuracy :  0.7366071428571429\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "        ('bow', CountVectorizer(  ngram_range=(1,2), stop_words= 'english')),  \n",
    "        ('tfidf', TfidfTransformer()),  \n",
    "        ('c',LinearSVC())\n",
    "    ])\n",
    "\n",
    "clf5 = pipeline.fit(X_train,y_train)\n",
    "pred=pipeline.predict(X_test)\n",
    "\n",
    "print(\"Classification results using LinearSVC\\n\")\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print(classification_report(y_test,pred))\n",
    "print(\"Accuracy : \",accuracy_score(pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification results using Random Forest\n",
      "[[14  0  0  2  1  0  1  1  0  0  1  0]\n",
      " [ 2 13  0  1  1  0  0  1  0  0  1  0]\n",
      " [ 2  1  8  0  0  0  6  0  0  1  0  0]\n",
      " [ 1  0  0 18  0  0  0  1  0  0  0  0]\n",
      " [ 1  0  1  1 11  0  0  1  0  1  0  0]\n",
      " [ 2  1  0  0  0 24  0  0  0  0  0  0]\n",
      " [ 1  1  2  0  0  0 17  1  0  0  0  0]\n",
      " [ 0  0  0  4  2  0  0 18  1  0  0  0]\n",
      " [ 2  0  0  1  0  0  1  0 13  0  1  0]\n",
      " [ 2  0  0  0  0  0  1  0  0 17  0  0]\n",
      " [ 1  2  0  0  0  0  0  0  0  0 13  0]\n",
      " [ 1  0  1  0  0  0  0  0  0  0  0  1]]\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "               AMA       0.48      0.70      0.57        20\n",
      "          AskIndia       0.72      0.68      0.70        19\n",
      "  Business/Finance       0.67      0.44      0.53        18\n",
      "              Food       0.67      0.90      0.77        20\n",
      "     Non-Political       0.73      0.69      0.71        16\n",
      "       Photography       1.00      0.89      0.94        27\n",
      "    Policy/Economy       0.65      0.77      0.71        22\n",
      "          Politics       0.78      0.72      0.75        25\n",
      "         Scheduled       0.93      0.72      0.81        18\n",
      "Science/Technology       0.89      0.85      0.87        20\n",
      "            Sports       0.81      0.81      0.81        16\n",
      "     [R]eddiquette       1.00      0.33      0.50         3\n",
      "\n",
      "          accuracy                           0.75       224\n",
      "         macro avg       0.78      0.71      0.72       224\n",
      "      weighted avg       0.77      0.75      0.75       224\n",
      "\n",
      "Accuracy :  0.7455357142857143\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "        ('bow', CountVectorizer(  ngram_range=(1,2), stop_words= 'english')),  \n",
    "        ('tfidf', TfidfTransformer()),  \n",
    "        ('c',RandomForestClassifier())\n",
    "    ])\n",
    "\n",
    "clf6 = pipeline.fit(X_train,y_train)\n",
    "pred=pipeline.predict(X_test)\n",
    "\n",
    "print(\"Classification results using Random Forest\")\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print(classification_report(y_test,pred))\n",
    "print(\"Accuracy : \",accuracy_score(pred,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['flair_predict.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(clf6, 'flair_predict.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
